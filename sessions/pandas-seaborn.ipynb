{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/logo.png)\n",
    "\n",
    "# Data analysis: Pandas and Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pandas__ is a very strong library for manipulating large and complex datasets using a new data structure, the **data frame**, which models a table of data.\n",
    "\n",
    "Pandas helps to close the gap between Python and R for data analysis and statistical computing.\n",
    "\n",
    "Pandas data frames address three deficiencies of NumPy arrays:\n",
    "\n",
    "- data frames hold heterogenous data; each column can have its own numpy.dtype,\n",
    "- the axes of a data frame are labeled with column names and row indices,\n",
    "- and, they account for missing values which this is not directly supported by arrays.\n",
    "\n",
    "Data frames are extremely useful for data manipulation.\n",
    "They provide a large range of operations such as filter, join, and group-by aggregation, as well as plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "print('Pandas version:', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Life History Traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze animal life-history data from [AnAge](http://genomics.senescence.info/download.html#anage). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/anage_data.txt', sep='\\t') # lots of other pd.read_... functions\n",
    "print(type(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas holds data in `DataFrame` (similar to __R__).\n",
    "\n",
    "`DataFrame` have a single row per observation (in contrast to the previous exercise in which each table cell has one observation), and each column has a single variable. \n",
    "\n",
    "Variables can be numbers or strings.\n",
    "\n",
    "The `head` method gives us the 5 first rows of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column attribute holds the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select a specific column:\n",
    "\n",
    "(note that the result is a view, not a new object!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyCol = data['Body mass (g)']\n",
    "print(type(bodyCol))\n",
    "print(len(bodyCol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look for the min / max value in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general min / max functions\n",
    "print(min(bodyCol))\n",
    "print(max(bodyCol))\n",
    "\n",
    "# pandas min/max - ignores missing values (nan)\n",
    "print(bodyCol.min())\n",
    "print(bodyCol.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine how many unique values there are in a specific column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Kingdom'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Phylum'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[1:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in data.columns[1:8]:\n",
    "    print('Unique {}:\\t{}'.format(elem, len(data[elem].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas `DataFrame` allows richer indexing.\n",
    "\n",
    "For example, let's browse our data for species that have body mass greater than 300 kg.\n",
    "\n",
    "First we will a create new column (`Series` object) that tells us if a row is a large animal row or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "large_index = data['Body mass (g)'] > 300 * 1000 # 300 kg\n",
    "large_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(large_index.shape)\n",
    "print(large_index.any())\n",
    "print(large_index.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can slice our data with this boolean index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data = data[large_index] # Note: this is not a new objec!\n",
    "large_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iterrows` method let's us iterate over the rows of the data.\n",
    "\n",
    "For each row we get both the row as a `Series` object (similar to `dict` for our use) and the row number as an `int` (this is similar to the use of `enumerate` on lists and strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in large_data.iterrows(): \n",
    "    print(row['Common name'], row['Body mass (g)']/1000, 'kg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... a [Dromedary](http://en.wikipedia.org/wiki/Dromedary) is the single-humped camel.\n",
    "\n",
    "![Camel](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Camelus_dromedarius_on_Sinai.jpg/220px-Camelus_dromedarius_on_Sinai.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Body mass (g)'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the first 3 measurements we see that there are quite a few missing values. \n",
    "\n",
    "NaN are slots that were empty in the data file.\n",
    "\n",
    "NaN values can be treated in many ways, one straightforward solution is simply remove these lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = data.dropna(subset = ['Body mass (g)', 'Metabolic rate (W)'])\n",
    "# drops a line if nan values is in subset\n",
    "\n",
    "clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean.hist('Body mass (g)');\n",
    "print((clean['Body mass (g)'] >  10 * 1000).sum())\n",
    "print((clean['Body mass (g)'] <  10 * 1000).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with small and medium animals - we filter out anything that has body mass of more than 10 kg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Body mass (g)'] <  10 * 1000] \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, let's plot a scatter of body mass vs. metabolic rate.\n",
    "\n",
    "Because we work with pandas, we can do that with the `plot` method of `DataFrame`, specifying the columns for `x` and `y` and a plotting style (without the style we would get a line plot which makes no sense here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.scatter(x='Body mass (g)', y='Metabolic rate (W)')\n",
    "plt.xlim(0,None)\n",
    "plt.ylim(0,None);\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this plot looks funny, you are probably using Pandas with version <0.22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot it seems that:\n",
    "1. there is a correlation between body mass and metabolic rate, and \n",
    "1. there are many small animals (less than 2 kg) and not many medium animals (between 5 and 10 kg).\n",
    "\n",
    "Before we continue, let's add another column that will show the mass in kg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Body mass (kg)'] = data['Body mass (g)'] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's check how many records do we have for each Class (as in the taxonomic unit): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = data['Class'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts['Mammalia']+class_counts['Aves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts.plot.bar()\n",
    "plt.ylabel('Num. of species');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have lots of mammals and birds, and a few reptiles and amphibians. \n",
    "\n",
    "This is important as amphibian and reptiles could have a different replationship between mass and metabolism because they are cold blooded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: data frames\n",
    "\n",
    "1) **Print the number** of reptiles in this dataset, and how many of them are of the genus `Python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reptiles = \n",
    "\n",
    "pythons = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of reptiles: \", reptiles)\n",
    "print(\"# of pythons: \", pythons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **Plot the histogram of the mammal body masses** using `plot.hist()`.\n",
    "\n",
    "Since most mammals are small, the histogram looks better if we plot a cumulative distribution rather then the distribution - we can do this with the `cumulative` argument. You also need to specify a higher `bins` argument then the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Seaborn\n",
    "\n",
    "Let's do a simple linear regression plot; but let's do it in separate for each Class. \n",
    "\n",
    "We can do this kind of thing with Matplotlib and [SciPy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html), but a very good tool for statistical visualizations is **[Seaborn](http://seaborn.pydata.org)**.\n",
    "\n",
    "Seaborn adds on top of Pandas a set of sophisticated statistical visualizations, similar to [ggplot2](http://ggplot2.org) for R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"talk\") # thist sets figure settings such as size of various elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(\n",
    "    x='Body mass (kg)', \n",
    "    y='Metabolic rate (W)', \n",
    "    hue='Class', \n",
    "    data=data, \n",
    "    ci=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `hue` means _color_, but it also causes _seaborn_ to fit a different linear model to each of the Classes. \n",
    "- `ci` controls the confidence intervals. I chose `False`, but setting it to `True` will show them.\n",
    "\n",
    "We can also seperate each class to a different plot (with the `col` argument):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    x='Body mass (kg)', \n",
    "    y='Metabolic rate (W)', \n",
    "    hue='Class', \n",
    "    col = 'Class',\n",
    "    data=data, \n",
    "    ci=True, \n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that mammals and birds have a clear correlation between size and metabolism and that it extends over a nice range of mass.\n",
    "\n",
    "So let's stick to mammals; next up we will see which orders of mammals we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammalia = data[data.Class=='Mammalia']\n",
    "order_counts = mammalia['Order'].value_counts()\n",
    "ax = order_counts.plot.barh()\n",
    "ax.set(\n",
    "    xlabel='Num. of species',\n",
    "    ylabel='Mammalia order'\n",
    ")\n",
    "ax.figure.set_figheight(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see we have alot of rodents and carnivores, but also a good number of bats (_Chiroptera_) and primates.\n",
    "\n",
    "Let's continue with orders that have at least 20 species - this also includes some cool marsupials like Kangaroo, Koala and [Taz](http://upload.wikimedia.org/wikipedia/en/c/c4/Taz-Looney_Tunes.svg) (Diprotodontia and Dasyuromorphia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = order_counts[order_counts >= 20]\n",
    "print(orders)\n",
    "abund_mammalia = mammalia[mammalia['Order'].isin(orders.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    x='Body mass (kg)', \n",
    "    y='Metabolic rate (W)', \n",
    "    hue='Order',\n",
    "    data=abund_mammalia, \n",
    "    ci=False, \n",
    "    height=8,\n",
    "    aspect=1.3,\n",
    "    line_kws={'lw':2, 'ls':'--'}, \n",
    "    scatter_kws={'s':50, 'alpha':0.5}\n",
    ");\n",
    "# if you get an error about height not being a keyword, change it to size or update seaborn: conda update seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is alot of data here we made the lines thinner - this can be done by giving _matplotlib_ keywords as a dictionary to the argument `line_kws` - and we made the markers bigger but with alpha (transperancy) 0.5 using the `scatter_kws` argument.\n",
    "\n",
    "Still ,there's too much data, and part of the problem is that some orders are large (e.g. primates) and some are small (e.g. rodents).\n",
    "\n",
    "Let's plot a separate regression plot for each order.\n",
    "We do this using the `col` and `row` arguments of `lmplot`, but in general this can be done for any plot using [seaborn's `FacetGrid` function](http://stanford.edu/~mwaskom/software/seaborn/tutorial/axis_grids.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    x='Body mass (kg)', \n",
    "    y='Metabolic rate (W)', \n",
    "    data=abund_mammalia, \n",
    "    hue='Order',\n",
    "    col='Order', \n",
    "    col_wrap=3, \n",
    "    ci=False, \n",
    "    scatter_kws={'s':40}, \n",
    "    sharex=False, \n",
    "    sharey=False\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the `sharex=False` and `sharey=False` arguments so that each Order will have a different axis range and so the data is spread nicely.\n",
    "\n",
    "There are plenty more types of figures, look at [seaborn galery](https://seaborn.pydata.org/examples/index.html).\n",
    "\n",
    "One more example - [jointplot](https://seaborn.pydata.org/examples/hexbin_marginals.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = mammalia[mammalia['Body mass (kg)'] < 1]\n",
    "sns.jointplot(\n",
    "    x='Body mass (kg)', \n",
    "    y='Metabolic rate (W)', \n",
    "    data=small, \n",
    "    kind='reg'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Some statistics__\n",
    "\n",
    "Lastly, let's do some quick statistics.\n",
    "\n",
    "First, calculate a summary of the the mammals using `describe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = abund_mammalia\n",
    "mass.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check if we can significantly say that the body mass of rodents is lower than that of carnivores.\n",
    "\n",
    "## Exercise: boxplot\n",
    "**Plot boxplots of the mammals body mass** using Seaborn, which is easier to use (and also makes nicer boxplots) then standard matplotlib boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data: abund_mammalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a t-test (implemented in the `scipy.stats` module) to test the hypothesis that there is *no difference* in body mass between rodents and carnivores.\n",
    "\n",
    "- `ttest_ind` calculates the t-test for the means of *two independent* samples of scores.\n",
    "- `scipy.stats` has many more statistical tests, distributions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carnivora_mass = abund_mammalia.loc[abund_mammalia['Order']=='Carnivora', 'Body mass (kg)']\n",
    "rodentia_mass = abund_mammalia.loc[abund_mammalia['Order']=='Rodentia', 'Body mass (kg)']\n",
    "\n",
    "res = ttest_ind(carnivora_mass, rodentia_mass, equal_var=False)\n",
    "print(res)\n",
    "print(\"P-value of t-test: {:.3g}\".format(res.pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Some more data manipulatoin__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will analyze a data regarding machines malfunctioning.\n",
    "\n",
    "For each machine, the data shows after how many hours it got broken, after how many hours a decision regarding the machine's status has been made, and the final status of the machine - whether it was fixed or sent for scrapping.\n",
    "\n",
    "For each machine we have the following parameters:\n",
    "* model\n",
    "* submodel\n",
    "* quality\n",
    "* type\n",
    "* stop (after how many hours the machine got broken)\n",
    "* diagonosis (after how many hours a decision regarding the machine has been made - either it was fixed or sent for scrapping)\n",
    "* fix-scrapping (0 means the machine was demolished, 1 means it was fixed)\n",
    "\n",
    "Let's look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'..\\data\\sim_data\\sim_part1.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we have 3 csv files: sim_part1, sim_part2, sim_part3\n",
    "\n",
    "We need to load them all, and merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = r'..\\data\\sim_data'\n",
    "files = os.listdir(folder)\n",
    "\n",
    "datas = [pd.read_csv(folder + '\\\\' + files[i]) for i in range(len(files))]\n",
    "\n",
    "# concatenate all datasets\n",
    "data = pd.concat(datas, axis = 0)\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many unique parameter values we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in data.columns[:4]: # run over the first 4 column names\n",
    "    print(param, '-', sorted(data[param].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all machines have the same model and submodel.\n",
    "\n",
    "So we can slice the data and focus on the parameters that do change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.drop(columns=['model', 'submodel']) # add: inplace=True if you wish to change the original data\n",
    "print(data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to add a column, that contains the duration of the fixing time (the diagnosis minus the stop).\n",
    "\n",
    "Note that in our records some processes ended with fixing (fix-scrapping = 1), and some with scrapping (fix-scrapping = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Add a column to `data` that contains, for each row, the `diagnosis` value, minus the `stop` value.\n",
    "\n",
    "For lines where fix-scrapping = 1, we want this subtraction result,\n",
    "\n",
    "but for lines where fix-scrapping = 0, we want the value in the column to be zero. \n",
    "\n",
    "Call the new column `fixtime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['fixtime'] = \n",
    "\n",
    "data2.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the fixtime only when the process finished with fixing (fix-scrapping=1).\n",
    "\n",
    "Currently, if for example we would want to get the average fixtime - if we will average the column we will have many 0 values.\n",
    "\n",
    "Possible solution - change 0 values to None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data2.fixtime[:12].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.loc[data2['fix-scrapping'] == 0, 'fixtime'] = np.nan\n",
    "print(data2.fixtime[:12].mean())\n",
    "data2.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now remove `diagnosis` column as we no longer need it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(columns=['diagnosis'], inplace=True)\n",
    "# The `inplace=True` command makes the function remove the column from the current DF and not make a new copy of the DF \n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to examine the effect of `quality`, `type` over the rest of the parameters. \n",
    "\n",
    "In order to do so we would like to extract all kinds of summary statistics for each `quality`, `type` couple.\n",
    "\n",
    "In order to do so we first need to state that we want to group our data according to `quality` and `type`.\n",
    "\n",
    "And then we need to aggregate the results with the desired operation (e.g. mean, variance, std etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data2.groupby(['quality', 'type'])\n",
    "aggdata = grouped.agg(np.mean)\n",
    "\n",
    "print(aggdata.shape)\n",
    "aggdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want more than one statistics? For example mean, std and len (= # of observations).\n",
    "\n",
    "We can specify for each column what are the operators we want to activate.\n",
    "\n",
    "We can do this using pandas [agg](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) method. The input of the method is a dictionary where: \n",
    "* the keys are the column names\n",
    "* the values are lists of functions/methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata = grouped.agg({'stop' : [np.mean, np.std, len], \\\n",
    "                       'fixtime' : [np.mean, np.std, len], \\\n",
    "                       'fix-scrapping' : [np.mean, np.std, len]})\n",
    "aggdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 'fixtime' column we wanted to consider only non-NaN values. \n",
    "\n",
    "np.mean and np.std indeed didn’t consider NaN values but len function did!\n",
    "\n",
    "In order to overcome this, we’ll define our own function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): # x is an array of values\n",
    "    '''this function returns the size of the array, \n",
    "    minus the number of nan values in that array'''\n",
    "    return (~np.isnan(x)).sum() # ~ is elementwise not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata = grouped.agg({'stop' : [np.mean, np.std, len],\n",
    "                       'fixtime' : [np.mean, np.std, f], # here we also set the names of the columns\n",
    "                       'fix-scrapping' : [np.mean, np.std, len]})\n",
    "aggdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata = grouped.agg({'stop' : [np.mean, np.std, len],\n",
    "                       'fixtime' : [('mean',np.mean), ('std',np.std), ('len',f)], # here we also set the names of the columns\n",
    "                       'fix-scrapping' : [np.mean, np.std, len]})\n",
    "aggdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata.reset_index(inplace=True)\n",
    "aggdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now present our data in a figure. We’ll make a 3-panels figure:\n",
    "* stop time\n",
    "* fixing time\n",
    "* fixing probability\n",
    "\n",
    "All three as a function of the quality parameter.\n",
    "\n",
    "Each panel will show two curves, one for type A and another for type B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by generating the formation of our figure:\n",
    "\n",
    "```py\n",
    "fig, ax = plt.subplots(1, 3, figsize = (16,5))\n",
    "```\n",
    "\n",
    "`plt.subplots` return 2 objects\n",
    "* A figure object\n",
    "* An array of axes  objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels = ['stop', 'fixtime', 'fix-scrapping']\n",
    "ylabels = ['Time to break', 'Fixing time', 'Fixing probability'] ###<->### for easy ylabels settings\n",
    "\n",
    "typeValues = ['A','B']\n",
    "xvec = sorted(data2['quality'].unique()) # generate x-axis\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (16,6))\n",
    "\n",
    "for i in range(3):  # in each iteration we’ll produce a different subplot\n",
    "    param = panels[i]\n",
    "    for j in range(2): # in each iteration we’ll produce a different curve\n",
    "        tval = typeValues[j]\n",
    "        \n",
    "        yvec = aggdata[aggdata['type'] == tval][param]['mean']\n",
    "        curdata_len = aggdata[aggdata['type'] == tval][param]['len']\n",
    "        ste = aggdata[aggdata['type'] == tval][param]['std'] / np.sqrt(curdata_len)\n",
    "        ax[i].errorbar(xvec, yvec, yerr = ste, fmt = '--o', label= 'type = '+tval) ###<->###\n",
    "    \n",
    "    ax[i].set_ylabel(ylabels[i], fontsize = 25)\n",
    "    ax[i].set_xlabel('quality', fontsize = 25)\n",
    "    ax[i].tick_params(labelsize = 20) # set tick labels size\n",
    "    ax[i].set_xticks(np.arange(6))\n",
    "    ax[i].set_xticklabels(np.arange(6))\n",
    "    if i == 2: ax[i].legend(fontsize=20, loc=0) # legend only in right panel\n",
    "    ax[i].set_title('ABC'[i], fontsize=30, fontweight='bold', y=1.07, x= -0.1)\n",
    "\n",
    "fig.tight_layout() # adjust the space between the panels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- Examples: [Seaborn example gallery](http://seaborn.pydata.org/examples/index.html)\n",
    "- Slides: [Statistical inference with Python](https://docs.google.com/presentation/d/1imQAEmNg4GB3bCAblauMOOLlAC95-XvkTSKB1_dB3Tg/pub?slide=id.p) by Allen Downey\n",
    "- Book: [Think Stats](greenteapress.com/thinkstats2/html/index.html) by Allen Downey - statistics with Python. Free Ebook.\n",
    "- Blog post: [A modern guide to getting started with Data Science and Python](http://twiecki.github.io/blog/2014/11/18/python-for-data-science/)\n",
    "- Tutorial: [An Introduction to Pandas](http://www.synesthesiam.com/posts/an-introduction-to-pandas.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colophon\n",
    "This notebook was written by [Yoav Ram](http://python.yoavram.com).\n",
    "\n",
    "The notebook was written using [Python](http://python.org/) 3.7.\n",
    "Dependencies listed in [environment.yml](../environment.yml).\n",
    "\n",
    "This work is licensed under a CC BY-NC-SA 4.0 International License.\n",
    "\n",
    "![Python logo](https://www.python.org/static/community_logos/python-logo.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
